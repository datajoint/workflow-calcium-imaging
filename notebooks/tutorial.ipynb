{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process calcium imaging data with DataJoint Elements\n",
    "\n",
    "This notebook will walk through processing two-photon calcium imaging data collected\n",
    "from ScanImage and processed with Suite2p.\n",
    "\n",
    "The DataJoint Python API and Element Calcium Imaging offer a lot of features to support collaboration, automation, reproducibility, and visualization.\n",
    "\n",
    "For more information on these topics, please visit our documentation: \n",
    " \n",
    "- [DataJoint Core](https://datajoint.com/docs/core/): General principles\n",
    "\n",
    "- DataJoint [Python](https://datajoint.com/docs/core/datajoint-python/) and\n",
    "  [MATLAB](https://datajoint.com/docs/core/datajoint-matlab/) APIs: in-depth reviews of\n",
    "  specifics\n",
    "\n",
    "- [DataJoint Element Calcium Imaging](https://datajoint.com/docs/elements/element-calcium-imaging/):\n",
    "  A modular pipeline for calcium imaging analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define schema prefixes and root data directory\n",
    "\n",
    "+ If we set prefix to `neuro_`, every schema created with the current workflow will start with `neuro_`, e.g. `neuro_lab`, `neuro_scan`, `neuro_imaging`, etc.\n",
    "\n",
    "+ The example dataset is mounted to this GitHub Codespace environment. Feel free to explore it in the `example_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"custom\"] = {\"database.prefix\": \"neuro_\",\n",
    "                       \"imaging_root_data_dir\": os.getenv('DJ_PUBLIC_S3_MOUNT_PATH', 'example_data')}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate DataJoint Elements\n",
    "\n",
    "+ The current workflow is composed of multiple database schemas, each of them corresponds to a module within `workflow_calcium_imaging.pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_calcium_imaging.pipeline import lab, subject, session, scan, imaging, Equipment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow diagram\n",
    "\n",
    "This workflow is assembled from 4 DataJoint elements:\n",
    "+ [element-lab](https://github.com/datajoint/element-lab)\n",
    "+ [element-animal](https://github.com/datajoint/element-animal)\n",
    "+ [element-session](https://github.com/datajoint/element-session)\n",
    "+ [element-calcium-imaging](https://github.com/datajoint/element-calcium-imaging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject.Subject)\n",
    "    + dj.Diagram(session.Session)\n",
    "    + dj.Diagram(scan)\n",
    "    + dj.Diagram(imaging)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert entries into manual tables and populate automated tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject1\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"ScanImage acquisition. Suite2p processing.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equipment.insert1(dict(scanner=\"ScanImage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = dict(subject=\"subject1\", session_datetime=\"2021-04-30 12:22:15.032\")\n",
    "\n",
    "session.Session.insert1(session_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.SessionDirectory.insert1(\n",
    "    dict(**session_key,\n",
    "        session_dir=\"subject1/session1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        scanner=\"ScanImage\",\n",
    "        acq_software=\"ScanImage\",\n",
    "        scan_notes=\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_settings = {\n",
    "                    \"display_progress\": True,\n",
    "                    \"reserve_jobs\": False,\n",
    "                    \"suppress_errors\": False,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration depends on your network bandwidth to s3\n",
    "scan.ScanInfo.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import suite2p\n",
    "\n",
    "params_suite2p = suite2p.default_ops()\n",
    "params_suite2p['nonrigid']=False\n",
    "\n",
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method=\"suite2p\",\n",
    "    paramset_idx=0,\n",
    "    params=params_suite2p,\n",
    "    paramset_desc=\"Calcium imaging analysis with Suite2p using default Suite2p parameters\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        paramset_idx=0,\n",
    "        task_mode='load', # load or trigger\n",
    "        processing_output_dir=\"subject1/session1/suite2p\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        paramset_idx=0,\n",
    "        curation_id=0,\n",
    "        curation_time=\"2021-04-30 12:22:15.032\",\n",
    "        curation_output_dir=\"subject1/session1/suite2p\",\n",
    "        manual_curation=False,\n",
    "        curation_note=\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Segmentation.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Fluorescence.populate(**populate_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query, fetch, and plot segmentations on average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image = (\n",
    "    imaging.MotionCorrection.Summary & session_key & \"field_idx=0\"\n",
    ").fetch1(\"average_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & session_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 130\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = np.zeros(np.shape(average_image), dtype=bool)\n",
    "for xpix, ypix in zip(mask_xpix, mask_ypix):\n",
    "    mask_image[ypix, xpix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(average_image)\n",
    "plt.contour(mask_image, colors=\"white\", linewidths=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop schemas\n",
    "\n",
    "+ Schemas are not typically dropped in a production workflow with real data in it. \n",
    "+ At the developmental phase, it might be required for the table redesign.\n",
    "+ When dropping all schemas is needed, the following is the dependency order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_databases(databases):\n",
    "    import pymysql.err\n",
    "    conn = dj.conn()\n",
    "\n",
    "    with dj.config(safemode=False):\n",
    "        for database in databases:\n",
    "            schema = dj.Schema(f'{dj.config[\"custom\"][\"database.prefix\"]}{database}')\n",
    "            while schema.list_tables():\n",
    "                for table in schema.list_tables():\n",
    "                    try:\n",
    "                        conn.query(f\"DROP TABLE `{schema.database}`.`{table}`\")\n",
    "                    except pymysql.err.OperationalError:\n",
    "                        print(f\"Can't drop `{schema.database}`.`{table}`. Retrying...\")\n",
    "            schema.drop()\n",
    "\n",
    "# drop_databases(databases=['imaging_report', 'imaging', 'scan', 'session', 'subject', 'lab', 'reference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
